{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpinitiative.data_preparation.data_management import DataManager\n",
    "from nlpinitiative.modeling import train\n",
    "\n",
    "from nlpinitiative.config import (\n",
    "    PROCESSED_DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddebcc771444828ad20bb02b3ff269b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/534 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d88af3696c41a19933ed0f24222a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016c8488859542e6a8d79297bd52197c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/534 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9615e17527426187d08069f3a55cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e48d39de7934ced8ff36b22f8c9544c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/534 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ff3b7797914f999027236d5254a205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "bin_data_obj, ml_data_obj = dm.prepare_and_preprocess_dataset('NLPinitiative_Master_Dataset.csv', PROCESSED_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading/Creating model objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_class_model = train.get_bin_model()\n",
    "ml_regress_model = train.get_ml_model()\n",
    "bin_class_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing training arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=0,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "average_tokens_across_devices=False,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=10,\n",
       "eval_strategy=IntervalStrategy.STEPS,\n",
       "eval_use_gather_object=False,\n",
       "evaluation_strategy=None,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=True,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=None,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_for_metrics=[],\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=2e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=C:\\Users\\Daniel\\Desktop\\GitHub\\NLPinitiative\\models\\binary_classification\\runs\\Mar17_21-06-22_DESKTOP-9BQTPM0,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=10,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=f1,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=3,\n",
       "optim=OptimizerNames.ADAMW_TORCH,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=C:\\Users\\Daniel\\Desktop\\GitHub\\NLPinitiative\\models\\binary_classification,\n",
       "overwrite_output_dir=True,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=C:\\Users\\Daniel\\Desktop\\GitHub\\NLPinitiative\\models\\binary_classification,\n",
       "save_on_each_node=True,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=10,\n",
       "save_strategy=SaveStrategy.STEPS,\n",
       "save_total_limit=5,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=None,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_liger_kernel=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_targs = train.bin_train_args(num_train_epochs=3)\n",
    "ml_targs = train.ml_regr_train_args(num_train_epochs=3)\n",
    "bin_targs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize trainer objects with metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x273c2ec8260>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_trainer = train.Trainer(\n",
    "    model=bin_class_model,\n",
    "    args=bin_targs,\n",
    "    train_dataset=bin_data_obj.encoded_dataset['train'],\n",
    "    eval_dataset=bin_data_obj.encoded_dataset['test'],\n",
    "    compute_metrics=train.compute_bin_metrics\n",
    ")\n",
    "\n",
    "ml_trainer = train.RegressionTrainer(\n",
    "    model=ml_regress_model,\n",
    "    args=ml_targs,\n",
    "    train_dataset=ml_data_obj.encoded_dataset['train'],\n",
    "    eval_dataset=ml_data_obj.encoded_dataset['test'],\n",
    "    compute_metrics=train.compute_reg_metrics\n",
    ")\n",
    "\n",
    "bin_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='201' max='201' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [201/201 08:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Auprc</th>\n",
       "      <th>Auroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.731000</td>\n",
       "      <td>0.687749</td>\n",
       "      <td>0.552174</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.276423</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.457836</td>\n",
       "      <td>0.383330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.684700</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.626087</td>\n",
       "      <td>0.637037</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.286604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.656100</td>\n",
       "      <td>0.641319</td>\n",
       "      <td>0.621739</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.373187</td>\n",
       "      <td>0.192918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.633500</td>\n",
       "      <td>0.620226</td>\n",
       "      <td>0.617391</td>\n",
       "      <td>0.582938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.736527</td>\n",
       "      <td>0.360478</td>\n",
       "      <td>0.142694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.646800</td>\n",
       "      <td>0.563656</td>\n",
       "      <td>0.769565</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.808664</td>\n",
       "      <td>0.356780</td>\n",
       "      <td>0.129397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.560300</td>\n",
       "      <td>0.534076</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.358176</td>\n",
       "      <td>0.133197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.488300</td>\n",
       "      <td>0.472513</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.869919</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.353433</td>\n",
       "      <td>0.112985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.432700</td>\n",
       "      <td>0.437693</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.351458</td>\n",
       "      <td>0.102956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.326500</td>\n",
       "      <td>0.419810</td>\n",
       "      <td>0.817391</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.830645</td>\n",
       "      <td>0.351859</td>\n",
       "      <td>0.105311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.305600</td>\n",
       "      <td>0.458250</td>\n",
       "      <td>0.769565</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.674797</td>\n",
       "      <td>0.757991</td>\n",
       "      <td>0.354017</td>\n",
       "      <td>0.117088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>0.414514</td>\n",
       "      <td>0.813043</td>\n",
       "      <td>0.781690</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.349357</td>\n",
       "      <td>0.091786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.318000</td>\n",
       "      <td>0.406273</td>\n",
       "      <td>0.813043</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>0.820084</td>\n",
       "      <td>0.349244</td>\n",
       "      <td>0.094446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.421959</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.739837</td>\n",
       "      <td>0.801762</td>\n",
       "      <td>0.349517</td>\n",
       "      <td>0.096573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.388481</td>\n",
       "      <td>0.830435</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.347785</td>\n",
       "      <td>0.085100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>0.401406</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.869919</td>\n",
       "      <td>0.849206</td>\n",
       "      <td>0.348013</td>\n",
       "      <td>0.086088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.108200</td>\n",
       "      <td>0.447563</td>\n",
       "      <td>0.817391</td>\n",
       "      <td>0.871560</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>0.348717</td>\n",
       "      <td>0.092774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.445220</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>0.347938</td>\n",
       "      <td>0.088595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.436645</td>\n",
       "      <td>0.830435</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.347578</td>\n",
       "      <td>0.085404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.442462</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.347633</td>\n",
       "      <td>0.086012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>0.445598</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.347741</td>\n",
       "      <td>0.086696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='201' max='201' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [201/201 11:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mean Rmse</th>\n",
       "      <th>Mean Mae</th>\n",
       "      <th>Mean R2</th>\n",
       "      <th>Mean Pearson</th>\n",
       "      <th>Rmse Per Cat</th>\n",
       "      <th>Mae Per Cat</th>\n",
       "      <th>R2 Per Cat</th>\n",
       "      <th>Pearson Per Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.095829</td>\n",
       "      <td>0.298064</td>\n",
       "      <td>0.202461</td>\n",
       "      <td>-0.414667</td>\n",
       "      <td>0.013832</td>\n",
       "      <td>[0.3388833999633789, 0.38174882531166077, 0.30464646220207214, 0.3350106477737427, 0.3081890642642975, 0.11990544199943542]</td>\n",
       "      <td>[0.29061469435691833, 0.22307737171649933, 0.20608055591583252, 0.21686230599880219, 0.18165791034698486, 0.09647236764431]</td>\n",
       "      <td>[-0.4235656261444092, -0.1805586814880371, -0.3667343854904175, -0.9992953538894653, -0.5178502798080444, 0.0]</td>\n",
       "      <td>[-0.004657868295907974, 0.049250200390815735, 0.003930327482521534, -0.049952954053878784, 0.07059164345264435, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>0.073658</td>\n",
       "      <td>0.257813</td>\n",
       "      <td>0.175469</td>\n",
       "      <td>-0.105107</td>\n",
       "      <td>0.038407</td>\n",
       "      <td>[0.3105452358722687, 0.35534268617630005, 0.2845039367675781, 0.2598612904548645, 0.25231873989105225, 0.08430837839841843]</td>\n",
       "      <td>[0.24069570004940033, 0.26183778047561646, 0.19290177524089813, 0.13224612176418304, 0.1558011770248413, 0.0693289265036583]</td>\n",
       "      <td>[-0.19543695449829102, -0.02288532257080078, -0.19197845458984375, -0.20293712615966797, -0.01740407943725586, 0.0]</td>\n",
       "      <td>[0.061859071254730225, 0.0628371387720108, 0.04372755065560341, -0.10217926651239395, 0.12579074501991272, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.068805</td>\n",
       "      <td>0.245605</td>\n",
       "      <td>0.177161</td>\n",
       "      <td>-0.047247</td>\n",
       "      <td>0.103978</td>\n",
       "      <td>[0.29291218519210815, 0.3540077209472656, 0.2641916275024414, 0.25237032771110535, 0.2553873360157013, 0.0547633059322834]</td>\n",
       "      <td>[0.2118823230266571, 0.30382779240608215, 0.17219732701778412, 0.1346803605556488, 0.19639083743095398, 0.043988462537527084]</td>\n",
       "      <td>[-0.06353509426116943, -0.015214085578918457, -0.02785050868988037, -0.1345829963684082, -0.042301058769226074, 0.0]</td>\n",
       "      <td>[0.1024453341960907, 0.16008910536766052, 0.13050183653831482, -0.10033231228590012, 0.2271880805492401, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.066395</td>\n",
       "      <td>0.241382</td>\n",
       "      <td>0.173711</td>\n",
       "      <td>-0.009641</td>\n",
       "      <td>0.150866</td>\n",
       "      <td>[0.28617167472839355, 0.3540746569633484, 0.25936123728752136, 0.245875284075737, 0.24504031240940094, 0.057766392827034]</td>\n",
       "      <td>[0.20312385261058807, 0.31358152627944946, 0.18641892075538635, 0.12100322544574738, 0.17018312215805054, 0.04795778915286064]</td>\n",
       "      <td>[-0.015150070190429688, -0.015598058700561523, 0.0093916654586792, -0.076934814453125, 0.040445804595947266, 0.0]</td>\n",
       "      <td>[0.10190166532993317, 0.23225104808807373, 0.19554685056209564, -0.06772571802139282, 0.292355477809906, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.068507</td>\n",
       "      <td>0.242712</td>\n",
       "      <td>0.152130</td>\n",
       "      <td>-0.043221</td>\n",
       "      <td>0.157752</td>\n",
       "      <td>[0.32561779022216797, 0.3445644676685333, 0.2528209090232849, 0.2504333555698395, 0.24055467545986176, 0.04228203371167183]</td>\n",
       "      <td>[0.19935685396194458, 0.23073866963386536, 0.15669964253902435, 0.17057593166828156, 0.12231255322694778, 0.03309778869152069]</td>\n",
       "      <td>[-0.31429600715637207, 0.038225650787353516, 0.05872219800949097, -0.11723387241363525, 0.07525485754013062, 0.0]</td>\n",
       "      <td>[0.013840929605066776, 0.23894715309143066, 0.2427712231874466, -0.018708568066358566, 0.31190699338912964, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.236018</td>\n",
       "      <td>0.142997</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.205221</td>\n",
       "      <td>[0.29397523403167725, 0.34065040946006775, 0.2523660659790039, 0.24728120863437653, 0.24088187515735626, 0.040956150740385056]</td>\n",
       "      <td>[0.17931558191776276, 0.23012839257717133, 0.1397620141506195, 0.1673528254032135, 0.10976901650428772, 0.03165317699313164]</td>\n",
       "      <td>[-0.07126879692077637, 0.0599520206451416, 0.06210601329803467, -0.08928608894348145, 0.07273757457733154, 0.0]</td>\n",
       "      <td>[0.08539795875549316, 0.2790977358818054, 0.2811932861804962, 0.025511320680379868, 0.35490694642066956, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.064088</td>\n",
       "      <td>0.234773</td>\n",
       "      <td>0.139810</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.252275</td>\n",
       "      <td>[0.2953828275203705, 0.3320983946323395, 0.2639731764793396, 0.24420779943466187, 0.2375115156173706, 0.03546601161360741]</td>\n",
       "      <td>[0.16770410537719727, 0.2367975115776062, 0.12152238190174103, 0.17410971224308014, 0.11210395395755768, 0.02662229724228382]</td>\n",
       "      <td>[-0.08155190944671631, 0.10655933618545532, -0.026151537895202637, -0.062377214431762695, 0.09850406646728516, 0.0]</td>\n",
       "      <td>[0.09075771272182465, 0.3535417318344116, 0.2849646806716919, 0.13819627463817596, 0.39391329884529114, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.061376</td>\n",
       "      <td>0.229971</td>\n",
       "      <td>0.157299</td>\n",
       "      <td>0.052546</td>\n",
       "      <td>0.303682</td>\n",
       "      <td>[0.28137052059173584, 0.34003394842147827, 0.24895383417606354, 0.23240743577480316, 0.23623237013816833, 0.04083087667822838]</td>\n",
       "      <td>[0.17637263238430023, 0.2972413897514343, 0.15576346218585968, 0.1110098659992218, 0.16993053257465363, 0.033473361283540726]</td>\n",
       "      <td>[0.018627047538757324, 0.0633513331413269, 0.08729702234268188, 0.03781247138977051, 0.10818809270858765, 0.0]</td>\n",
       "      <td>[0.1922324150800705, 0.3726108968257904, 0.30492478609085083, 0.20584037899971008, 0.4428021013736725, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.060334</td>\n",
       "      <td>0.227885</td>\n",
       "      <td>0.144133</td>\n",
       "      <td>0.057784</td>\n",
       "      <td>0.329769</td>\n",
       "      <td>[0.3026777505874634, 0.31854918599128723, 0.25015565752983093, 0.2307867705821991, 0.22725047171115875, 0.03788924589753151]</td>\n",
       "      <td>[0.17006544768810272, 0.2313154935836792, 0.1435249298810959, 0.14266176521778107, 0.14865434169769287, 0.02857867069542408]</td>\n",
       "      <td>[-0.13563263416290283, 0.17797470092773438, 0.07846355438232422, 0.051185011863708496, 0.1747148633003235, 0.0]</td>\n",
       "      <td>[0.1407794952392578, 0.4526047706604004, 0.29660865664482117, 0.27078261971473694, 0.48807018995285034, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.057751</td>\n",
       "      <td>0.223270</td>\n",
       "      <td>0.141758</td>\n",
       "      <td>0.090523</td>\n",
       "      <td>0.363802</td>\n",
       "      <td>[0.29084497690200806, 0.3129344582557678, 0.2481420487165451, 0.22791039943695068, 0.22133953869342804, 0.03845089301466942]</td>\n",
       "      <td>[0.16813690960407257, 0.21950159966945648, 0.15273906290531158, 0.13397076725959778, 0.14672087132930756, 0.02948027290403843]</td>\n",
       "      <td>[-0.0485762357711792, 0.2066972255706787, 0.09323954582214355, 0.0746883749961853, 0.2170889973640442, 0.0]</td>\n",
       "      <td>[0.19369232654571533, 0.48648712038993835, 0.3071897625923157, 0.296794056892395, 0.5348472595214844, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.055026</td>\n",
       "      <td>0.218078</td>\n",
       "      <td>0.141829</td>\n",
       "      <td>0.124864</td>\n",
       "      <td>0.397251</td>\n",
       "      <td>[0.2801477015018463, 0.30615234375, 0.2450377345085144, 0.22529453039169312, 0.2137666791677475, 0.03806992620229721]</td>\n",
       "      <td>[0.17555372416973114, 0.22678735852241516, 0.15849794447422028, 0.12581564486026764, 0.1344224214553833, 0.029899505898356438]</td>\n",
       "      <td>[0.02713841199874878, 0.24071049690246582, 0.11578512191772461, 0.09580731391906738, 0.2697451114654541, 0.0]</td>\n",
       "      <td>[0.23648682236671448, 0.5159376859664917, 0.34596407413482666, 0.32013049721717834, 0.5677362680435181, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.055579</td>\n",
       "      <td>0.219750</td>\n",
       "      <td>0.134654</td>\n",
       "      <td>0.118849</td>\n",
       "      <td>0.428187</td>\n",
       "      <td>[0.29083549976348877, 0.30423709750175476, 0.2406177669763565, 0.22559240460395813, 0.2136400192975998, 0.043575894087553024]</td>\n",
       "      <td>[0.1516609489917755, 0.19667799770832062, 0.137843519449234, 0.13897310197353363, 0.1494302898645401, 0.03333762288093567]</td>\n",
       "      <td>[-0.0485081672668457, 0.2501809000968933, 0.1473962664604187, 0.09341472387313843, 0.2706102728843689, 0.0]</td>\n",
       "      <td>[0.21381710469722748, 0.5763335227966309, 0.4160596430301666, 0.3588147461414337, 0.5759083032608032, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.051800</td>\n",
       "      <td>0.052080</td>\n",
       "      <td>0.213050</td>\n",
       "      <td>0.137661</td>\n",
       "      <td>0.160111</td>\n",
       "      <td>0.463707</td>\n",
       "      <td>[0.2796323299407959, 0.29088717699050903, 0.23378302156925201, 0.22162531316280365, 0.21000123023986816, 0.04236878827214241]</td>\n",
       "      <td>[0.1575452834367752, 0.20664848387241364, 0.1645478755235672, 0.1145142987370491, 0.14904269576072693, 0.03366855904459953]</td>\n",
       "      <td>[0.03071451187133789, 0.314541220664978, 0.19514471292495728, 0.125019371509552, 0.29524505138397217, 0.0]</td>\n",
       "      <td>[0.2765788435935974, 0.5940451622009277, 0.476033091545105, 0.3707282543182373, 0.6011514067649841, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.049415</td>\n",
       "      <td>0.207430</td>\n",
       "      <td>0.136913</td>\n",
       "      <td>0.197342</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>[0.2679440379142761, 0.28889283537864685, 0.23040899634361267, 0.21950729191303253, 0.19533921778202057, 0.04248479753732681]</td>\n",
       "      <td>[0.17536795139312744, 0.20843961834907532, 0.1624271720647812, 0.12360730022192001, 0.11728575825691223, 0.03435128927230835]</td>\n",
       "      <td>[0.11005103588104248, 0.32390815019607544, 0.218208909034729, 0.14166343212127686, 0.3902198076248169, 0.0]</td>\n",
       "      <td>[0.33434849977493286, 0.5974829196929932, 0.5037763714790344, 0.40269824862480164, 0.6317261457443237, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>0.048572</td>\n",
       "      <td>0.206123</td>\n",
       "      <td>0.136412</td>\n",
       "      <td>0.208188</td>\n",
       "      <td>0.516550</td>\n",
       "      <td>[0.2663836181163788, 0.2853868007659912, 0.2272745668888092, 0.21824447810649872, 0.19414080679416656, 0.04530728980898857]</td>\n",
       "      <td>[0.16704358160495758, 0.1940183937549591, 0.1670362949371338, 0.12699773907661438, 0.12709608674049377, 0.036278385668992996]</td>\n",
       "      <td>[0.12038636207580566, 0.340218722820282, 0.2393348217010498, 0.15151095390319824, 0.39767879247665405, 0.0]</td>\n",
       "      <td>[0.35561782121658325, 0.6188434958457947, 0.5380936861038208, 0.4201442003250122, 0.650050163269043, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.047322</td>\n",
       "      <td>0.203028</td>\n",
       "      <td>0.130989</td>\n",
       "      <td>0.225838</td>\n",
       "      <td>0.534332</td>\n",
       "      <td>[0.266478568315506, 0.28346922993659973, 0.21973291039466858, 0.21683336794376373, 0.1880655139684677, 0.04358978196978569]</td>\n",
       "      <td>[0.1647629290819168, 0.18910500407218933, 0.14767681062221527, 0.12852372229099274, 0.12161439657211304, 0.03424965590238571]</td>\n",
       "      <td>[0.119759202003479, 0.3490554094314575, 0.2889796495437622, 0.16244769096374512, 0.4347860813140869, 0.0]</td>\n",
       "      <td>[0.35981959104537964, 0.6315712332725525, 0.5697880983352661, 0.43899425864219666, 0.6714860200881958, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.045997</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.128618</td>\n",
       "      <td>0.243291</td>\n",
       "      <td>0.544729</td>\n",
       "      <td>[0.2627091407775879, 0.2802332937717438, 0.21749179065227509, 0.21455644071102142, 0.1824437975883484, 0.04254336655139923]</td>\n",
       "      <td>[0.17279797792434692, 0.197159081697464, 0.13648909330368042, 0.11737224459648132, 0.11467725038528442, 0.03321214020252228]</td>\n",
       "      <td>[0.1444857120513916, 0.36383235454559326, 0.3034094572067261, 0.17994534969329834, 0.46807223558425903, 0.0]</td>\n",
       "      <td>[0.381633460521698, 0.6217912435531616, 0.5854988098144531, 0.44551247358322144, 0.6892085075378418, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.045604</td>\n",
       "      <td>0.199597</td>\n",
       "      <td>0.130633</td>\n",
       "      <td>0.247969</td>\n",
       "      <td>0.552981</td>\n",
       "      <td>[0.26120293140411377, 0.27816545963287354, 0.2148442268371582, 0.213547483086586, 0.1851029098033905, 0.04471898823976517]</td>\n",
       "      <td>[0.17071592807769775, 0.2074509561061859, 0.13547305762767792, 0.1145525872707367, 0.1208290234208107, 0.034778397530317307]</td>\n",
       "      <td>[0.15426748991012573, 0.37318623065948486, 0.32026565074920654, 0.18763983249664307, 0.45245361328125, 0.0]</td>\n",
       "      <td>[0.39621591567993164, 0.6238939762115479, 0.6003044843673706, 0.45378804206848145, 0.6907005310058594, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.045139</td>\n",
       "      <td>0.198995</td>\n",
       "      <td>0.129570</td>\n",
       "      <td>0.252026</td>\n",
       "      <td>0.561623</td>\n",
       "      <td>[0.26141557097435, 0.27291813492774963, 0.21318958699703217, 0.21226805448532104, 0.18809424340724945, 0.04608534649014473]</td>\n",
       "      <td>[0.1642061024904251, 0.19633108377456665, 0.1352345049381256, 0.11891084164381027, 0.12696759402751923, 0.035768359899520874]</td>\n",
       "      <td>[0.15288996696472168, 0.3966115713119507, 0.33069533109664917, 0.1973448395729065, 0.4346134066581726, 0.0]</td>\n",
       "      <td>[0.4027112126350403, 0.6436053514480591, 0.6078892350196838, 0.46311888098716736, 0.6907888650894165, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.045043</td>\n",
       "      <td>0.198780</td>\n",
       "      <td>0.128656</td>\n",
       "      <td>0.253098</td>\n",
       "      <td>0.564099</td>\n",
       "      <td>[0.2624914050102234, 0.2717278301715851, 0.21319590508937836, 0.21206070482730865, 0.18698643147945404, 0.04621630534529686]</td>\n",
       "      <td>[0.1623489260673523, 0.19304658472537994, 0.1332998126745224, 0.1213894709944725, 0.1258970946073532, 0.03595445305109024]</td>\n",
       "      <td>[0.14590322971343994, 0.4018634557723999, 0.33065569400787354, 0.19891220331192017, 0.44125378131866455, 0.0]</td>\n",
       "      <td>[0.399972140789032, 0.6503671407699585, 0.6103190183639526, 0.46811866760253906, 0.6917181611061096, nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bin_eval_res, ml_eval_res = train.train(bin_trainer=bin_trainer, ml_trainer=ml_trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Best Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'HF TOKEN GOES HERE'\n",
    "train.upload_best_models(token=token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPinitiative-sAkSWYnk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

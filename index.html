<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="ASU Capstone Group 8 / J Healthcare Initiative" />
      <link rel="shortcut icon" href="img/favicon.ico" />
    <title>About This Project - NLPInitiative</title>
    <link rel="stylesheet" href="css/theme.css" />
    <link rel="stylesheet" href="css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="assets/_mkdocstrings.css" rel="stylesheet" />
        <link href="style/style.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "About This Project";
        var mkdocs_page_input_path = "index.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="." class="icon icon-home"> NLPInitiative
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">About</span></p>
              <ul class="current">
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">About This Project</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#project-links">Project Links</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#table-of-contents">Table of Contents</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#setup">Setup</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#commands">Commands</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#structure">Structure</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#datasets">Datasets</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#ethos">ETHOS</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#multitarget-conan">Multitarget-CONAN</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#license">License</a>
    </li>
    </ul>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">User Guide</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="notebooks/Data_Import_Notes/">Data Importing and Normalization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="notebooks/Data_Processing/">Data Preprocessing and Tokenization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="notebooks/Model_Training/">Model Training, Evaluation and Deployment</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="notebooks/Inference_Demo/">Model Inference</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Module Documentation</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="dataset-management/">Dataset Management</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="model-management/">Model Training, Evaluation and Inference</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href=".">NLPInitiative</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">About</li>
      <li class="breadcrumb-item active">About This Project</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="nlpinitiative-documentation">NLPInitiative Documentation</h1>
<p><a href="#license"><img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-yellow.svg" /></a></p>
<p>Codebase for training, evaluating and deploying NLP models used to detect discriminatory language targeting marginallized individuals or communities and the type(s) of discrimination detected.</p>
<p>This project was developed in coordination with the <strong><a href="https://www.j-initiative.org/" style="text-decoration:none">The J-Healthcare Initiative</a></strong> for the purposes of detecting discriminatory language in textual media from public officials/organizations and news agencies targetting marginalized communities communities.</p>
<h2 id="project-links">Project Links</h2>
<ul>
<li><strong><a href="https://huggingface.co/dlsmallw/NLPinitiative-Binary-Classification" style="text-decoration:none">ðŸ¤— NLPinitiative-Binary-Classification</a></strong> - The fine-tuned binary classfication models HF Model Repository.</li>
<li><strong><a href="https://huggingface.co/dlsmallw/NLPinitiative-Multilabel-Regression" style="text-decoration:none">ðŸ¤— NLPinitiative-Multilabel-Regression</a></strong> - The fine-tuned multilabel regression models HF Model Repository.</li>
<li><strong><a href="https://huggingface.co/datasets/dlsmallw/NLPinitiative-Dataset" style="text-decoration:none">ðŸ¤— NLPinitiative-Dataset</a></strong> - The HF hosted Dataset Repository.</li>
<li><strong><a href="https://huggingface.co/spaces/dlsmallw/NLPinitiative-Streamlit-App" style="text-decoration:none">ðŸ¤— HF Spaces Streamlit Web Application</a></strong> - The HF Space hosting the served models.</li>
</ul>
<hr />
<h2 id="table-of-contents">Table of Contents</h2>
<ul>
<li><a href="#setup">Setup</a></li>
<li><a href="#structure">Structure</a></li>
<li><a href="#datasets">Datasets</a></li>
<li><a href="#license">License</a></li>
</ul>
<hr />
<h2 id="setup">Setup</h2>
<p>For the purposes of easily building, setting up and managing the project codebase, a bash script, <code>setup.sh</code>, has been created which contains a suite of custom commands for running various development-related processes (defined below). Use of this script requires that a bash shell is installed and set up (git bash for Windows users). For configuring and setting up your system to enable the use of Linux subsystems (Windows users), please see <a href="https://www.google.com/search?client=firefox-b-d&amp;q=Microsoft+windows+bash">this</a> for details on how to install and enabling WSL.</p>
<p>This script can be activated by entering <code>source ./setup.sh</code> within the bash shell while within the project source directory.</p>
<h4 id="commands">Commands</h4>
<ul>
<li><code>help</code>: Displays all of the commands that can be used.</li>
<li><code>build</code>: This will setup a virtual environment within the project source directory and install all necessary dependencies for development.</li>
<li><code>clean</code>: This will deactivate the virutal environment, and remove the .venv directory (uninstalling all dependencies).</li>
<li><code>docs build</code>: Parses the docstrings in the project and generates the project documentation using mkdocs.</li>
<li><code>docs serve</code>: Serves the mkdocs documentation to a local dev server that can be opened in a browser.</li>
<li><code>docs deploy</code>: Deploys the mkdocs documentation to the linked GitHub repositories 'GitHub Pages'.</li>
<li><code>lint</code>: Lints (analyzes and identifies style/format issues to correct) the project files.</li>
<li><code>format</code>: Corrects the issues identified from running the lint command.</li>
<li><code>run tests</code>: Runs the test suite..</li>
<li><code>set bin_repo &lt;HF Model Repository ID&gt;</code>: Sets the binary model repository ID to the specified string.<ul>
<li>This is the source for downloading the model tensor file.</li>
</ul>
</li>
<li><code>set ml_repo &lt;HF Model Repository ID&gt;</code>: Sets the multilabel regression model repository ID to the specified string.<ul>
<li>This is the source for downloading the model tensor file.</li>
</ul>
</li>
<li><code>set ds_repo &lt;HF Dataset Repository ID&gt;</code>: Sets the dataset repository ID to the specified string.<ul>
<li>This is the source for downloading the datasets.</li>
</ul>
</li>
<li><code>set streamlit_repo &lt;HF Spaces Streamlit App Repository ID&gt;</code>: Sets the Streamlit App repo ID in the pyproject.toml file.</li>
<li><code>set space_url &lt;HF Spaces base URL&gt;</code>: Sets the base URL for HF Spaces in the pyproject.toml file.</li>
<li><code>set model_url &lt;HF Model Repo base URL&gt;</code>: Sets the base URL for HF Model Repos in the pyproject.toml file.</li>
<li><code>set dataset_url &lt;HF Dataset Repo base URL&gt;</code>:  Sets the base URL for HF Dataset Repos in the pyproject.toml file.</li>
<li><code>set hf_token &lt;HF Token&gt;</code>: Sets the HF personal token in the pyproject.toml file.</li>
</ul>
<hr />
<h2 id="structure">Structure</h2>
<pre><code>â”œâ”€â”€ data
â”‚   â”œâ”€â”€ interim                 &lt;- Intermediate datasets that have been normalized
â”‚   â”œâ”€â”€ normalization_schema    &lt;- The schema used for normalizing 3rd party datasets
â”‚   â”œâ”€â”€ processed               &lt;- The final merged dataset consisting of all normalized datasets
â”‚   â””â”€â”€ raw                     &lt;- The original, raw datasets prior to normalization
â”‚
â”œâ”€â”€ docs            &lt;- A directory containing documentation used for generating and serving 
â”‚                      project documentation
â”‚
â”œâ”€â”€ models          &lt;- Trained and serialized models, model predictions, or model summaries
â”‚   â”‚
â”‚   â”œâ”€â”€ binary_classification        &lt;- Trained and serialized binary classification 
â”‚   â”‚                                   models/model predictions/model summaries
â”‚   â””â”€â”€ multilabel_regression        &lt;- Trained and serialized multilabel regression 
â”‚                                       models/model predictions/model summaries
â”‚
â”œâ”€â”€ nlpinitiative   &lt;- Source code for use in this project
â”‚   â”‚
â”‚   â”œâ”€â”€ __init__.py             &lt;- Makes nlpinitiative a Python module
â”‚   â”œâ”€â”€ config.py               &lt;- Store useful variables and configuration
â”‚   â””â”€â”€ modeling                &lt;- Source code for model training and inference
â”‚       â”‚                
â”‚       â”œâ”€â”€ __init__.py         &lt;- Makes modeling a Python module
â”‚       â”œâ”€â”€ predict.py          &lt;- Code to run model inference with trained models          
â”‚       â””â”€â”€ train.py            &lt;- Code to train models
â”‚
â”œâ”€â”€ notebooks           &lt;- Directory containing Jupyter notebooks detailing research, testing and 
â”‚                          example usage of project modules 
â”‚
â”œâ”€â”€ references          &lt;- Directory containing Data dictionaries, manuals, and all other 
â”‚                          explanatory materials
â”‚
â”œâ”€â”€ LICENSE             &lt;- Open-source license if one is chosen
â”‚
â”œâ”€â”€ mkdocs.yml          &lt;- mkdocs project configuration
â”‚
â”œâ”€â”€ Pipfile             &lt;- The project dependency file for reproducing the analysis environment, 
â”‚                          e.g., generated with `pipenv install`
â”‚
â”œâ”€â”€ Pipfile.lock        &lt;- Locked file containing hashes for dependencies
â”‚
â”œâ”€â”€ pyproject.toml      &lt;- Project configuration file with package metadata for nlpinitiative and 
â”‚                          configuration for tools like black
â”‚
â”œâ”€â”€ README.md           &lt;- The top-level README for developers using this project
â”‚
â”œâ”€â”€ setup.cfg           &lt;- Configuration file for flake8
â”‚
â””â”€â”€ setup.sh            &lt;- Bash script containing convenience commands for managing the project
</code></pre>
<p><span>
    Based on the CookieCutter Data Science project structure template 
    <a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
        <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
    </a>
</span></p>
<hr />
<h2 id="datasets">Datasets</h2>
<h3 id="ethos">ETHOS</h3>
<p>A collection consisting of binary and multilabel data containing hate speech from social media.</p>
<ul>
<li><a href="https://doi.org/10.1007/s40747-021-00608-2">Academic Article</a></li>
<li><a href="https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset">Link to Source GitHub Repository</a><ul>
<li><a href="https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset/blob/master/ethos/ethos_data/Ethos_Dataset_Binary.csv">Direct Link to the Binary Dataset</a></li>
<li><a href="https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset/blob/master/ethos/ethos_data/Ethos_Dataset_Multi_Label.csv">Direct Link to the Multilabel Dataset</a></li>
</ul>
</li>
</ul>
<pre><code class="language-bibtex">@article{mollas_ethos_2022,
    title = {{ETHOS}: a multi-label hate speech detection dataset},
    issn = {2198-6053},
    url = {https://doi.org/10.1007/s40747-021-00608-2},
    doi = {10.1007/s40747-021-00608-2},
    journal = {Complex \&amp; Intelligent Systems},
    author = {Mollas, Ioannis and Chrysopoulou, Zoe and Karlos, Stamatis and Tsoumakas, Grigorios},
    month = jan,
    year = {2022},
}
</code></pre>
<h3 id="multitarget-conan">Multitarget-CONAN</h3>
<p>Multi-Target CONAN is a dataset of hate speech/counter-narrative pairs for English comprising several hate targets, collected using a Human-in-the-Loop approach.</p>
<ul>
<li><a href="https://doi.org/10.1007/s40747-021-00608-2">Academic Article</a></li>
<li><a href="https://github.com/marcoguerini/CONAN">Link to Source GitHub Repository</a><ul>
<li><a href="https://github.com/marcoguerini/CONAN/blob/master/Multitarget-CONAN/Multitarget-CONAN.csv">Direct Link to the Dataset</a></li>
</ul>
</li>
</ul>
<pre><code class="language-bibtex">@inproceedings{fanton-2021-human,
  title=&quot;{Human-in-the-Loop for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate Speech}&quot;,
  author=&quot;{Fanton, Margherita and Bonaldi, Helena and TekiroÄŸlu, Serra Sinem and Guerini, Marco}&quot;,
  booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics&quot;,
  month = aug,
  year = &quot;2021&quot;,
  publisher = &quot;Association for Computational Linguistics&quot;,
}
</code></pre>
<hr />
<h2 id="license">License</h2>
<p>The MIT License (MIT)
Copyright (c) 2025, ASU Fall-2024/Spring-2025 Capstone Group 8 and The J Healthcare Initiative</p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p>
<p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p>
<p>THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>
<hr />
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="notebooks/Data_Import_Notes/" class="btn btn-neutral float-right" title="Data Importing and Normalization">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
      <span><a href="notebooks/Data_Import_Notes/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="js/jquery-3.6.0.min.js"></script>
    <script>var base_url = ".";</script>
    <script src="js/theme_extra.js"></script>
    <script src="js/theme.js"></script>
      <script src="search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
